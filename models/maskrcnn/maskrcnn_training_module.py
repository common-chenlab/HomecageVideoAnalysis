import cv2
import os
import sys

ROOT_DIR = os.path.abspath(os.path.join("objectdetection", "maskrcnn"))
sys.path.append(ROOT_DIR)

from mrcnn import utils
from mrcnn import model as modellib
import custom

# import utilities
import utils

config = custom.CustomConfig()

class InferenceConfig(config.__class__):
    # changes for inferencing.
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
config = InferenceConfig()

class MaskRCNNTrainingModule():
    def __init__(self, trained_height, trained_width, weights_path, preferred_aspect_ratio = None, confidence_thresh = 0.80, verbose = False):  
        """"" MaskRCNN python class used to initialize image segmentation model/weights and run inference

        Parameters
        ----------
        trained_width: int
        Width of the frames used to train neural network

        trained_height: int
        Height of the frames used to train neural network 

        weights_path: str
            Full path to .h5 file generated by MaskRCNN script 

        preferred_aspect_ratio: float
        Aspect ratio to use when cropping frames

        confidence_thresh: float
        Confidence threshold used to ignore predictions below this threshold

        verbose: boolean
            Choose to print process to command window
        """

        self.trained_width = trained_width
        self.trained_height = trained_height
        self.preferred_aspect_ratio = preferred_aspect_ratio
        self.confidence_thresh = confidence_thresh
        self.weights_path = weights_path
        self.verbose = verbose

        # # TODO: Remove this when done debugging
        # self.weights_path = r'Z:\Dropbox\Chen Lab Dropbox\Chen Lab Team Folder\Projects\Home_Cage_Training\DeepLabCut\ObjectDetection\cage\cilse_cages\cageview_v3\weights\mask_rcnn_cage_ls_06132022.h5'
        
        # make sure weights file exists
        if not os.path.isfile(self.weights_path):
            raise ValueError(f'Weights path "{self.weights_path}" does not point to a file.')

        # device used to run model
        self.DEVICE = "/cpu:0"  # /cpu:0 or /gpu:0

        # load maskrcnn model architecture
        MODEL_DIR = os.path.join(ROOT_DIR, "logs")
        self.model = modellib.MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=config)

        self.model.load_weights(self.weights_path, by_name=True)

        if self.verbose:
            print("Successfully loaded in MaskRCNN model!\n")


    def run_inference(self, frame, DEBUG = False):
        """ get cage view position and mask from single [frame]"""

        # dim of input frame
        height, width = frame.shape[:2]

        # compare aspect ratio vs. trained aspect ratio
        # note: continue analysis but send warning to alert aspect ratio discrepancy
        if round(width/height, 1) != round(self.trained_width/self.trained_height, 1):
            print('Warning: Aspect ratio of input frame is not equal to aspect ratio of trained frames for maskrcnn')

        # resize input frame
        frame = cv2.resize(frame, (self.trained_width, self.trained_height))

        # run mask rcnn inference
        # note: verbose = 0 to ignore output to terminal
        results = self.model.detect([frame], verbose=0)

        # parse prediction
        boxes, masks, confidences = results[0]['rois'], results[0]['masks'], results[0]['scores']
        N = boxes.shape[0]

        if self.verbose:
            # number of objects detected in image
            print('Number of objects detected by maskrcnn:', N)

            # confidences of each detected object
            print('Confidences:', confidences)

        # note: maskrcnn masks are sometimes smaller than the actual object. Dilate predicted mask
        # to increase area of mask/including more of frame
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (6,6))
        kernel_iterations = 4

        object_results = []

        # loop through all objects detected from maskrcnn
        for i in range(N):

            # filter objects below confidence threshold
            obj_confidence = confidences[i]
            if obj_confidence < self.confidence_thresh:
                print('Warning: Skipping object #{} since it has a low confidence level [{}]'.format(str(i), str(round(obj_confidence, 3))))
                continue

            # object results
            box, mask = boxes[i], masks[:,:,i]

            # re-format cage position coordinates
            y1, x1, y2, x2 = box
            obj_position = x1/self.trained_width, y1/self.trained_height, (x2-x1)/self.trained_width, (y2-y1)/self.trained_height

            # change obj_position coordinates to have custom aspect ratio
            if self.preferred_aspect_ratio:
                obj_position = utils.resize_cropped_frame(position = obj_position, max_width = self.trained_width, 
                    max_height = self.trained_height, aspect_ratio = self.preferred_aspect_ratio)


            # convert mask of 0/1 to 0/255 for opencv
            obj_mask = mask.astype("uint8") * 255

            # resize and dilate mask detected
            obj_mask = cv2.dilate(obj_mask, kernel, iterations = kernel_iterations)
            obj_mask = cv2.resize(obj_mask, (width, height))

            # return object position and mask
            object_results.append({'position': obj_position, 'mask': obj_mask}) 

            # debug
            if DEBUG:
                # view results of maskrcnn
                frame_cpy = frame.copy()

                # mask frame
                frame_cpy[~(obj_mask == 255)] = 0
                frame_cpy = frame_cpy

                # crop frame
                x, y, w, h = obj_position
                x, y, w, h = int(x*self.trained_width), int(y*self.trained_height), int(w*self.trained_width), int(h*self.trained_height)
                frame_cpy = frame_cpy[y:y+h, x:x+w]
                
                cv2.imshow("mask#{}".format(str(i)), frame_cpy)
                cv2.waitKey(0)

        # sort objects based on position in frame (left -> right)
        sorted_object_results = sorted(object_results, key=lambda d: d['position'][0]) 

        return sorted_object_results